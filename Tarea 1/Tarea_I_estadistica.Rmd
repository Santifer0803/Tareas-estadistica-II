---
title: "Tarea 1"
author: Alejandro Brenes (C21319), Santiago Fernández (C22943), Eyeri Méndez (C24765)
date: "`r Sys.Date()`"
output: 
  pdf_document:
    latex_engine: xelatex
    highlight: tango
    extra_dependencies: ["fontspec"]
header-includes:
  - \setmainfont{Times New Roman}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE)
suppressPackageStartupMessages(library(dplyr))
```

Inicialmente, se cargan todas las librerías necesarias para la tarea.

```{r librerias}
pacman::p_load(readxl,
               dplyr,
               univariateML,
               rriskDistributions,
               ks,
               boot,
               ggplot2,
               cowplot)
```

Se lee la base de datos necesaria.

```{r base_datos}
BaseSalarios <- read_excel("BaseSalarios.xlsx")
```

Se corrige el formato de algunas columnas.

```{r formato_columnas}
BaseSalarios$Fec.Nac <- as.Date(BaseSalarios$Fec.Nac)

BaseSalarios <- BaseSalarios %>%
  rename(Cuotas = Coutas)
```

Ahora se procede con los ejercicios.

## Parte I

### 1)

Agregamos la categoría de nivel, en esta, se pondrá un $1$ si la observación tiene menos de $150$ cuotas y $2$ si se tienen más o igual cantidad de cuotas, pues no se especifica qué hacer con las personas que tienen exactamente las $150$ cuotas.

```{r categoria_nivel}
BaseSalarios <- BaseSalarios %>% 
  mutate(Nivel = ifelse(Cuotas < 150, "1", "2"))
```

### 2)

Generamos una tabla resumen con los requisitos solicitados.

```{r tabla_res}
(resumen <- BaseSalarios %>% 
  group_by(Nivel) %>% 
  summarise(prom_sal = mean(U.Salario, na.rm = TRUE),
            prom_sex = mean(Sexo, na.rm = TRUE),
            var_sal = var(U.Salario, na.rm = TRUE),
            var_sex = var(Sexo, na.rm = TRUE),
            cant_sal = length(U.Salario),
            cant_sex = length(Sexo),
            max_sal = max(U.Salario, na.rm = TRUE),
            max_sex = max(Sexo, na.rm = TRUE),
            min_sal = min(U.Salario, na.rm = TRUE),
            min_sex = min(Sexo, na.rm = TRUE)))
```

### 3)

El diagrama de caja, o diagrama de cajas y bigotes, es un gráfico que muestra la distribución de los datos con $5$ puntos principales, el máximo, el mínimo y los $3$ cuartiles de los datos, es decir, muestra los $4$ cuartiles de la muestra de datos y sus extremos. Junto a toda esa información, se logra observar una medida de tendencia central (mediana), medidas de dispersión (el rango y el rango intercuartílico) y la simetría o asimetría de una función, pues los datos pueden estar concentrados en alguno de los extremos de la distribución, en el centro o en un punto medio de estos (Flores, J., & Flores, R. 2018).

### 4)

Se presenta ahora el gráfico de cajas y bigotes para la variable del salario, filtrando por la categoría Nivel.

```{r plotbox}
BaseSalarios %>% 
  ggplot(aes(x = Nivel, y = U.Salario, fill = Nivel)) +
  geom_boxplot() +
  labs(title = "Boxplot del salario según Nivel", x = "Nivel", y = "Salario") +
  theme_cowplot()
```


### 5)

Hay una diferencia clara con respecto a los niveles, las personas que tienen $150$ o más cuotas presentan un salario más alto en general, esto se puede comprobar visualmente con los cuartiles de las $2$ cajas, pues, el percentil $75\%$ del nivel $1$ está casi igual que el percentil $25\%$ del nivel $2$, lo cual denota una gran diferencia en cuanto a salarios entre los niveles.

De la mano con lo anterior, se puede ver que el punto en donde más se concentran datos en el nivel $2$ (la mediana, representada por la línea del centro de la caja azul), superaría el percentíl $75\%$ del nivel $1$, mostrando, una vez más, la gran diferencia entre ambos niveles.

Por otro lado, es interesante la cantidad de valores atípicos, fuera del rango intercuartílico, aunque no se puede determinar una cantidad exacta visualmente, se logra observar que en el nivel $2$ hay múltiples valores que superan el máximo del nivel $1$, evidenciando que las personas que se encuentran en este último tienen un salario de, a lo sumo, $4 .000 .000$, mientras que en el otro grupo se encuentran varias observaciones por encima de este valor, llegando a superar los $6. 000. 000$.

### 6)

Usando la prueba de hipótesis, se presenta el siguiente resultado.

```{r prueba_hip}
# Filtramos las observaciones de nivel 1 para salarios
salarios.n1 <- BaseSalarios %>% 
  filter(Nivel == "1") %>% 
  select(U.Salario)

prom.n2 <- resumen[[2, 2]]

t.test(salarios.n1, mu = prom.n2, alternative = "less", conf.level = 0.95)
```

Para esta prueba de hipótesis nos centraremos, inicialmente, en la hipótesis nula, esta dice que la media verdadera (del nivel $1$) es mayor o igual a la media del nivel $2$. La respuesta a esta pregunta se puede ver con el p-valor resultante de la prueba, el cual es exactamente:

```{r p-valor}
t.test(salarios.n1, mu = prom.n2, alternative = "less", conf.level = 0.95)$p.value
```

Recordemos que el p-valor indica que si se asume la hipótesis nula cierta, la probabilidad de que sea realmente verdadera. En este caso, hay una probabilidad de exactamente $0$ de que la media del nivel $1$ sea mayor o igual a la media del nivel $2$, lo cual refuerza la conclusión del inciso anterior.

## Parte II

### 1)

El histograma vendría dado por:

```{r histograma}
BaseSalarios %>%
  ggplot(aes(x = Cuotas)) +
  geom_histogram(fill = "seagreen3", color = "black") +
  labs(title = "Histograma de las cuotas", x = "Cantidad de cuotas", y = "Densidad") +
  theme_cowplot()
```


### 2)

Iniciamos con el kernel biweight.

```{r kernel_biweight}
D <- density(BaseSalarios$Cuotas, kernel = "biweight")
hist(
  BaseSalarios$Cuotas,
  main = "Kernel Biweight",
  freq = FALSE,
  col = "khaki4",
  xlab = "Cuotas",
  ylab = "Densidad"
)
lines(D,
      lwd = 2,
      lty = 1,
      col = "darkolivegreen3")
```

Seguimos con el kernel gaussiano.

### 3)

## Parte III

### 1)

El Criterio de Información de Akaike (AIC) es una herramienta objetiva que cuantifica la idoneidad de un modelo específico en comparación con un conjunto limitado de modelos. Ofrece un método sencillo y objetivo para seleccionar el modelo más apropiado para describir los datos observados ().

Por lo tanto, el Criterio de Información de Akaike es una medida utilizada para comparar y seleccionar modelos estadísticos, especialmente en contextos donde se emplea la máxima verosimilitud. El AIC se basa en la idea de evaluar tanto la calidad del ajuste del modelo como su complejidad, y su fórmula está dada por:

AIC = $2k - 2ln(\hat{L})$,

donde $k$ es el número de parámetros libres del modelo y $\hat{L}$ es la función de máxima verosimilitud.

Este método nos da una aproximación de la distancia entre el modelo y el verdadero proceso que genera los datos observados, el cual es desconocido y a veces hasta difícil de definir. Dado que la estimación está basada en los datos observados, esta distancia es siempre relativa y depende del conjunto de datos que se utilizó. Por lo tanto, un valor de AIC no tiene un significado por sí mismo, sino que es interpretable al compararse con otros valores de AIC utilizando los mismos datos observados ().

En este sentido, el término $2k$ penaliza la complejidad del modelo, previniendo que este sea demasiado complejo, lo cual podría llevar a un sobreajuste, mientras que el término $-2ln(\hat{L})$ representa el ajuste del modelo a los datos. Un valor más bajo indicaría un mejor ajuste.

Por lo tanto, el AIC equilibra el ajuste del modelo con su simplicidad, penalizando la adición de parámetros que no mejoran significativamente el ajuste del modelo. De esta manera, cuando se comparan dos o más modelos, el modelo preferido es el que tiene el AIC más bajo, ya que significa que el modelo logra un buen equilibrio entre simplicidad y ajuste a los datos.

### 2)

```{r 3.2}
comparacion.univariate <- model_select(BaseSalarios$Cuotas, 
                                       models = c("exp", "gamma", "lnorm", 
                                                  "weibull", "lgamma", "unif"), 
                                       criterion = "aic",
                                       na.rm = TRUE)
comparacion.univariate
```

### 3)

```{r 3.3}
comparacion.rrisk <- fit.cont(BaseSalarios$Cuotas)
```

### 4)

Como se puede observar en el dataframe del punto anterior, bajo el criterio del AIC, la distribución Weibull es la que más se aproxima a la variable Cuotas, el cual es el mismo resultado que en el punto 2 de esta parte. Además, los parámetros de dicha distribución obtenidos en los puntos 2 y 3 son prácticamente los mismos, por lo que se decide seleccionar la distribución Weibull como la más idónea para los datos de la variable Cuotas.

### 5)

Con la distribución seleccionada, se procede a construir un intervalo de confianza para la media y la desviación estándar de la variable Cuotas.

```{r 3.5}
ic.media <- bootstrapml(comparacion.univariate, map = mean)
ic.desv.est <- bootstrapml(comparacion.univariate, map = sd)

ic.media
ic.desv.est
```

## Parte IV

### 1)

El propósito de la función kde() es poder realizar una estimación de densidad de núcleo (kernel density estimation) en uno o varios puntos. No se asume una forma específica de la distribución para estimar la densidad de probabilidad del conjunto de datos observados. Es compatible con diferentes tipos de kernel. Devuelve un objeto del tipo 'kde' y los resultados más importantes que incluye son "eval.points" que corresponden a los datos para el eje x y "estimate" que corresponde a la densidad asignada.  

A continuación un ejemplo con la columna 'Cuotas': 

```{r 4.1 kde_con_cuotas}
cuotas.kde <- kde(x = BaseSalarios$Cuotas)

cuotas.kde.df <- data.frame(x = cuotas.kde$eval.points, 
                     y = cuotas.kde$estimate)

ggplot(cuotas.kde.df, aes(x = x, y = y)) +
  geom_line(color = "darkblue", size = 1.2) + 
  labs(title = "Estimación de Densidad Kernel para las cuotas",
       x = "Valores",
       y = "Densidad") +
  theme_minimal(base_size = 14)
```

### 2)

La función boot.ci() se utiliza con el propósito de calcular intervalos de confianza para estimaciones obtenidas a través de un proceso de Bootstrap. Además, proporciona diferentes tipos de intervalos de confianza. Esta función toma como entrada un objeto de la clase boot, generado a partir de la función boot(), que contiene los resultados del procedimiento bootstrap.

### 3)

Ahora, el próposito es estimar la media $\mu$ para las cuotas. Dado que para la prueba Bootstrap se escogieron $1000$ muestras, el estimador seria: 

\[\hat{\theta} = \frac{1}{1000} \sum_{i = 1}^{1000} {\bar{x_i}}\]

A continuacion, la prueba Bootstrap usando boot(): 
```{r 4.3 prueba_Bootsrap}

resultados.boot <- boot(data = BaseSalarios$Cuotas, 
                        statistic = function(data, indices)
                        mean(data[indices]), 
                        R = 1000)
print(resultados.boot)
```

Teniendo los resultados, procedemos con la comparacion: 
```{r 4.3 comparacion}
media.bootstrap <- mean(resultados.boot$t)  
media.original <- resultados.boot$t0       

print(paste("Media Bootstrap:", media.bootstrap))
print(paste("Media Original:", media.original))
```

Como se vio anteriormente, se confirma el sesgo de $0.02018587$. Finalmente, realiza el histograma de la prueba Bootstrap: 
```{r 4.3 histograma_Bootsrap}
plot(resultados.boot)
```


## Referencias

[Martínez, D. R., Albín, J. L., Cabaleiro, J. C., Pena, T. F., Rivera, F. F., & Blanco, V. (2009, septiembre). El criterio de información de Akaike en la obtención de modelos estadísticos de rendimiento. XX Jornadas de Paralelismo, A Coruña, España] (https://www.researchgate.net/profile/Tomas-Pena/publication/236279245_El_criterio_de_informacion_de_Akaike_en_la_obtencion_de_modelos_estadisticos_de_Rendimiento/links/58904fa3aca272bc14be3600/El-criterio-de-informacion-de-Akaike-en-la-obtencion-de-modelos-estadisticos-de-Rendimiento.pdf)

[Flores, J., & Flores, R. (2018). La enseñanza del diagrama de caja y bigotes para mejorar su interpretación. Revista Bases de la Ciencia. e-ISSN 2588-0764, 3(1), 69-75.](https://revistas.utm.edu.ec/index.php/Basedelaciencia/article/download/1107/1102)

kde function - RDocumentation. (2017). Rdocumentation.org. https://www.rdocumentation.org/packages/ks/versions/1.10.7/topics/kde

boot.ci function - RDocumentation. (2024). Rdocumentation.org. https://www.rdocumentation.org/packages/boot/versions/1.3-31/topics/boot.ci
